{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we provide an example (Diving48) on how to prepare 2D skeleton data for custom video datasets.\n",
    "You can run each step in this notebook or implement them on your own. \n",
    "\n",
    "**Step 1**: Download Videos and Annotations from the official website of Diving48: http://www.svcl.ucsd.edu/projects/resound/dataset.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Videos and Annotations\n",
    "!wget http://www.svcl.ucsd.edu/projects/resound/Diving48_V2_train.json\n",
    "!wget http://www.svcl.ucsd.edu/projects/resound/Diving48_V2_test.json\n",
    "!wget http://www.svcl.ucsd.edu/projects/resound/Diving48_rgb.tar.gz\n",
    "# Extract the videos\n",
    "!tar -xf Diving48_rgb.tar.gz\n",
    "# After that, the folder structure will looks like:\n",
    "# WorkingDirectory\n",
    "# ├── Diving48_V2_train.json\n",
    "# ├── Diving48_V2_test.json\n",
    "# `-- rgb\n",
    "#     ├-- _8Vy3dlHg2w_00000.mp4\n",
    "#     ├-- _8Vy3dlHg2w_00001.mp4\n",
    "#     ├-- _8Vy3dlHg2w_00004.mp4\n",
    "#     ├-- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After extracting videos successfully, you can now remove the tar.gz file\n",
    "!rm Diving48_rgb.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Generate video list for 2d skeleton extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import load, dump\n",
    "from pyskl.smp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load('Diving48_V2_train.json')\n",
    "test = load('Diving48_V2_test.json')\n",
    "tmpl = 'examples/extract_diving48_skeleton/rgb/{}.mp4'\n",
    "\n",
    "lines = [(tmpl + ' {}').format(x['vid_name'], x['label']) for x in train + test]\n",
    "mwlines(lines, 'diving48.list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Extract 2D skeleton for Diving48 Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/pyskl\n",
      "+ SCRIPT=tools/data/custom_2d_skeleton.py\n",
      "+ GPUS=8\n",
      "+ MKL_SERVICE_FORCE_INTEL=1\n",
      "++ dirname tools/dist_run.sh\n",
      "+ PYTHONPATH=tools/..:\n",
      "+ python -m torch.distributed.launch --nproc_per_node=8 --master_port=23029 tools/data/custom_2d_skeleton.py --video-list examples/extract_diving48_skeleton/diving48.list --out examples/extract_diving48_skeleton/diving48_annos.pkl\n",
      "/root/anaconda3/envs/pyskl/lib/python3.7/site-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  FutureWarning,\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pthload checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n",
      "\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\" to /root/.cache/torch/hub/checkpoints/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n",
      "100%|████████████████████████████████████████| 158M/158M [00:14<00:00, 11.2MB/s]\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n",
      "  0%|                                                  | 0/2125 [00:00<?, ?it/s]/workspaces/pyskl/mmdetection/mmdet/datasets/utils.py:70: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n",
      "  0%|                                                  | 0/2124 [00:00<?, ?it/s]/workspaces/pyskl/mmdetection/mmdet/datasets/utils.py:70: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n",
      "/workspaces/pyskl/mmdetection/mmdet/datasets/utils.py:70: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n",
      "/workspaces/pyskl/mmdetection/mmdet/datasets/utils.py:70: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n",
      "/workspaces/pyskl/mmdetection/mmdet/datasets/utils.py:70: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n",
      "/workspaces/pyskl/mmdetection/mmdet/datasets/utils.py:70: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n",
      "/workspaces/pyskl/mmdetection/mmdet/datasets/utils.py:70: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n",
      "  0%|                                                  | 0/2125 [00:00<?, ?it/s]/workspaces/pyskl/mmdetection/mmdet/datasets/utils.py:70: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n",
      "100%|█████████████████████████████████████| 2125/2125 [9:25:20<00:00, 15.96s/it]\n",
      "100%|█████████████████████████████████████| 2124/2124 [9:28:40<00:00, 16.06s/it]\n",
      "100%|█████████████████████████████████████| 2125/2125 [9:39:43<00:00, 16.37s/it]\n",
      "100%|█████████████████████████████████████| 2124/2124 [9:43:02<00:00, 16.47s/it]\n",
      "100%|█████████████████████████████████████| 2125/2125 [9:44:29<00:00, 16.50s/it]\n",
      "100%|█████████████████████████████████████| 2125/2125 [9:46:12<00:00, 16.55s/it]\n",
      "100%|█████████████████████████████████████| 2125/2125 [9:47:25<00:00, 16.59s/it]\n",
      "100%|█████████████████████████████████████| 2124/2124 [9:51:21<00:00, 16.71s/it]\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/workspaces/pyskl/')\n",
    "print(os.getcwd())\n",
    "# Extract 2D skeletons of diving48 videos with 8 GPUs (it may take around 12 hours). The video_list is diving48.list  the output file is diving48.pkl\n",
    "!bash tools/dist_run.sh tools/data/custom_2d_skeleton.py 8 --video-list examples/extract_diving48_skeleton/diving48.list --out examples/extract_diving48_skeleton/diving48_annos.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: Merge extracted 2D skeletons and split information to get the final annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('examples/extract_diving48_skeleton')\n",
    "train = load('Diving48_V2_train.json')\n",
    "test = load('Diving48_V2_test.json')\n",
    "annotations = load('diving48_annos.pkl')\n",
    "split = dict()\n",
    "split['train'] = [x['vid_name'] for x in train]\n",
    "split['test'] = [x['vid_name'] for x in test]\n",
    "dump(dict(split=split, annotations=annotations), 'diving48_hrnet.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you get the 2D skeleton annotations for diving48. We also provide the generated pickle file at https://download.openmmlab.com/mmaction/pyskl/data/diving48/diving48_hrnet.pkl. You can download this pickle file to check if it's the same as your generated pickle file. We also provide a [config file](https://github.com/kennymckormick/pyskl/blob/main/configs/posec3d/slowonly_r50_gym/joint.py) for training on diving48 and release the trained weights and accuracy number in [PoseC3D](https://github.com/kennymckormick/pyskl/blob/main/configs/posec3d/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "61a57a4b5406d2de388e2f91097d4e4bcd7d5f4a46f53a795aa28a02eed27fc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
